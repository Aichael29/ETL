# ETL
cahier des charges pour un projet d'ETL pipeline

## Objectif :

Créer un pipeline ETL pour extraire des données à partir de sources multiples, les transformer et les charger dans une base de données.

## Fonctionnalités clés :

Extraction de données à partir de sources multiples telles que des fichiers CSV, des bases de données MySQL et des API externes.
Transformation de données en utilisant des techniques telles que la normalisation, la concaténation, la jointure, l'agrégation et la conversion de type de données.
Chargement des données dans une base de données, telle que MySQL ou PostgreSQL, avec une gestion des erreurs efficace pour minimiser les pertes de données.
Planification de l'exécution du pipeline ETL pour une automatisation régulière de l'ensemble du processus.
Documentation complète du processus ETL et des données stockées dans la base de données.

## Technologies utilisées :

Python pour l'écriture du code ETL et pour les tests unitaires.
SQL pour la création et la gestion de la base de données.
Outils tels que pandas, numpy, sqlalchemy, cron pour l'automatisation du processus.

## Livraison :

Code source complet, avec des instructions d'installation et d'exécution détaillées.
Documentation complète, y compris des diagrammes d'architecture et des spécifications techniques.
